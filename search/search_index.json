{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Manchester Analysis Facility help pages","text":"<p>Some description of the docs</p>"},{"location":"#contributing","title":"Contributing","text":"<p>The documentation source is hosted on GitHub in maf-helpdesk repository.</p> <p>To serve the docs locally, you can clone the repo and use <code>mkdocs</code> see your changes.</p> <pre><code>git clone https://github.com/MANHEP/maf-helpdesk.git\ncd maf-helpdesk\npython -m venv .venv &amp;&amp; source .venv/bin/activate\npython -m pip install -r requirements.txt\nmkdocs serve\n</code></pre> <p>You will see a link to open a locally hosted version of the documentation pages in a browser. These will auto-update with changes to the source files.</p>"},{"location":"Certificates/","title":"How to get certificates","text":"<p>x509 certificates in the UK are provided by the UK e-Science CA. There are different tools but for users the easiest is to go through the WEB portal. Ignore the other methods.</p> <p>During the process you will be asked to select your institution RA (Registration Authority). RA operators are the staff responsible to check your request is genuine. For Manchester there are historically two RA units, you should select the Manchester HEP. Rather than emailing anyone specifically you should contact the RA operators using the blackett-support@listserv.manchester.ac.uk so the request can be followed by who is available.</p> <p>The proccess of requesting a certificate is a pre-requisite to register to a VO (Virtual Organisation) and is a separate procedure usually carried out by different set of administrators particularly for what concerns large VOs such as the LHC experiments. Occasionally, in Manchester the people are the same because we manage the GridPP VOMS which supports a number of smaller groups.</p>"},{"location":"Certificates/#new-certificates","title":"New Certificates","text":"<p>New certificates have an approval procedure which must be followed to demonstrate the person requesting the certificate is who they say they are and are part of the University of Manchester. There are two procedures one in person and, since covid, one virtual one.</p>"},{"location":"Certificates/#in-person","title":"In person","text":"<p>The basic procedure in person requires that you bring an ID document and possibly your university card. The ID document needs to be scanned so if you have a scanned copy you can preventively send it to the operator that will check it matches. The operator also has to verify the PIN you used during the certificate request. </p>"},{"location":"Certificates/#virtual-on-zoom","title":"Virtual (on zoom)","text":"<p>The virtual procedure requires that you show the the same documents and the same scans but on top of this you will also need to show that you can connect to the UK Federation service using your university credentials. This has to happen during the video call not before.</p> <p>The zoom room to use will be comunicated via email.</p>"},{"location":"Certificates/#renewals","title":"Renewals","text":"<p>If you used to have a certificate but you let it expire it is possible that the RA might ask you to go through the same procedure above again. Do not let it expire!</p> <p>For a normal renewal while your certificate is still valid instead only the PIN is required and it can all be handled automatically.</p>"},{"location":"Certificates/#managing-certificates","title":"Managing certificates","text":"<p>Once the procedure is completed you'll receive an email telling you can download the certificate. After this you will have a copy in your browser which needs to be exported and converted from a single P12 file format to two files: a public and a private key in PEM format that you can use with grid tools. All the commands and explanations you need are on this useful page</p>"},{"location":"Certificates/#cern-certificates","title":"CERN certificates","text":"<p>People on LTA at CERN can request a CERN certificate. The procedure is completely different and you can find the information on the CERN CA site. Manchester RAs are not responsible for CERN certificates.</p>"},{"location":"noether_acceptable_use/","title":"Noether Compute Cluster: Acceptable Use","text":""},{"location":"noether_acceptable_use/#preamble","title":"Preamble","text":"<p>This document has been written to provide end-users of the Noether Compute Cluster (hereafter the cluster, Noether or the equipment) with directions as to acceptable use of the equipment. In the first instance it is addressed to staff and postgraduate students in the HEP Group of the Department of Physics and Astronomy (hereafter the group) at the University of Manchester, but it is expected that all and any persons who are, or may become, affiliated with the group and who wish to use Noether shall have recourse to it before access is granted. It is not intended to be a technical description of, or instruction manual for Noether smallcaps}: please see the FAQ for the the latter.</p>"},{"location":"noether_acceptable_use/#terminology","title":"Terminology","text":"<p>We deem a the actions of an end-user of Noether to be unacceptable if it they are in potential breach of United Kingdom law, the University's general regulations and statutes, the rules set forth in the document Acceptable Use Policy - IT Facilities and Services or if they fail to accord with the instructions herein mandated. We deem usage to be inappropriate when it fails to be professional, collegial or courteous by academic workplace standards, or when it generally does not accord with such guidelines as may be set forth in the present document.</p>"},{"location":"noether_acceptable_use/#breaches","title":"Breaches","text":"<p>Any breach of acceptable use is liable to incur summary termination of the offending user's batch jobs and shell sessions on Noether and temporary suspension of that user's account. Thesis supervisors, affiliated PIs and the Head of Group may be consulted in confidence when this action is initiated. Access will be restored as and when all parties are satisfied that no intentional repeat of the breach will occur. We shall deal leniently with inappropriate use, unless it becomes habitual, in which case again, the academic superiors of the culpable party are liable to be consulted.</p>"},{"location":"noether_acceptable_use/#requesting-an-account","title":"Requesting an Account","text":"<p>Accounts on Noether are in the first instance available to postgraduates and staff in the group, but subject to consideration, academic collaborators on Campus or beyond may also be eligible. Postgraduates requesting an account must be sponsored by their Supervisor or PI. Accounts are requested by sending an email to the BLACKETT-SUPPORT mailing list. Requests will usually be actioned within one working day of receipt. There is no charge for an account.</p>"},{"location":"noether_acceptable_use/#home-directories","title":"Home Directories","text":"<p>Users are granted a home directory with a small initial selection of 'dotfiles' and sample HTCondor scripts: this directory are subject to a quota as specified in the FAQ; if you require additional capacity, you must request it via BLACKETT-SUPPORT.</p>"},{"location":"noether_acceptable_use/#expiry-of-accounts","title":"Expiry of Accounts","text":"<p>Accounts are by default suspended when their owner's leaving date (as recorded by Campus HR) is attained. Of course dispensations to keep accounts active beyond this point may be countenanced subject to the approval of the Head of Group. After six months from the date of suspension, all files and data on Noether directly owned by the account, including the home directory, are liable to be made unavailable, and the account itself deactivated.</p>"},{"location":"noether_acceptable_use/#group-membership","title":"Group Membership","text":"<p>Your Noether account will receive a POSIX group id corresponding to to your primary experimental affiliation and you will have access to a corresponding data area. You may not source or copy data from any other experimental data location without permission: if you have obtained that permission please forward the evidence in an email to BLACKETT-SUPPORT and we will adjust your account accordingly.</p>"},{"location":"noether_acceptable_use/#connecting-to-noether","title":"Connecting to Noether","text":"<p>Only account-holders are permitted to connect to Noether connections shall be to the designated login node only and an ssh client must be used. It is permissible for users to authenticate to the cluster by means of ssh-key, provided that key is protected by a non-trivial (strong) passphrase.</p>"},{"location":"noether_acceptable_use/#the-batch-system","title":"The Batch System","text":"<p>All end-users of Noether are expected to employ the cluster's HTCondor batch scheduler: all intensive and non-trivial computational tasks, including long compilations, must be submitted to it, whereupon they will be allocated to a work-node. It is absolutely prohibited to subvert the batch system by logging directly on to work-nodes: users must run interactive sessions (other than their login shell) under the aegis of HTCondor; a small number of work-nodes have been set aside for this purpose.</p>"},{"location":"noether_acceptable_use/#obtaining-support","title":"Obtaining Support","text":"<p>If the answer to your support request is not contained in the FAQ then please send an email to BLACKETT-SUPPORT This mailing list is read by the cluster's systems administrators: they should respond to queries within one working day.</p>"},{"location":"noether_acceptable_use/#conclusion","title":"Conclusion","text":"<p>These regulations have been approved by the Head of Group and IT Team, Particle Physics in the University of Manchester. Should additions or amendments transpire from time to time, they will be announced in the BLACKETT-SUPPORT mailing list, and this document will be updated accordingly, the current version being posted at the present location. </p>"},{"location":"noether_basic_usage/","title":"Noether Compute Cluster: Basic Usage","text":""},{"location":"noether_basic_usage/#what-is-noether","title":"What is Noether?","text":"<p>Noether is a Linux compute cluster being made available to members of the HEP Group for exploratory high-throughput computation.</p> <p>The cluster presently consists of a login node, which can be accessed from the internet, job-scheduling nodes, which are restricted to the sysadmins, and a number of work-nodes, which are available to end-users via the login node only under the aegis the HTCondor batch schduler.</p>"},{"location":"noether_basic_usage/#getting-an-account-and-first-login","title":"Getting an Account and First Login","text":"<p>As expained in the FAQ, to request an account on Noether, please ask your supervisor/line manager to send an email to the BLACKETT-SUPPORT mailing list. When your request is approved, you will be supplied out-of-band with an initial set of login credentials.</p> <p>Then to connect to Noether for the first time please <code>ssh</code> with your supplied username to <code>noether.hep.manchester.ac.uk</code>. Please note that if you are connecting from off-Campus you will need to install an initialise the GlobalProtect VPN tool provided by IT Services. On your initial connection attempt the supplied password will need to be changed, as in the following sample <code>ssh</code> session:</p> <pre><code>    $ ssh mrtest@noether.hep.manchester.ac.uk\n    Password: *******                                            # &lt;---- enter the issued password\n    WARNING: Your password has expired.\n    You must change your password now and login again!\n    Changing password for user mrtest.\n    Current Password: *******                                    # &lt;---- enter the issued password AGAIN\n    New password: ************                                   # &lt;---- now choose a NEW password\n    Retype new password: ************                            # &lt;---- re-enter your NEW password\n    passwd: all authentication tokens updated successfu lly.\n    Connection to noether.hep.manchester.ac.uk closed.\n</code></pre> <p>The next time you <code>ssh</code> to Noether, entering the new password will give you a shell session on the Noether:</p> <pre><code>    $ ssh mrtest@noether.hep.manchester.ac.uk\n    mrtest@noether.hep.manchester.ac.uk's password: ************\n    [mrtest@vm119 ~]$                                            # &lt;---- On Noether's login node!\n</code></pre>"},{"location":"noether_basic_usage/#interactive-sessions","title":"Interactive Sessions","text":"<p>Use of the login node for heavy computational work is prohibited: users are expected to conduct intensive interactive shell sessions the clusters work-nodes, some of which have been set aside for this purpose. Now directly ssh-ing to a work-node is not permitted: users should issue the command <code>condor_submit -i</code> or the alias <code>qrsh</code>  as in the following example:</p> <pre><code>    $ condor_submit -i  getenv=True\n    1 job(s) submitted to cluster 2724.\n    Welcome to slot1_1@wn3801320.hep.manchester.ac.uk!\n    You will be logged out after 7200 seconds of inactivity.\n    [mrtest@wn3801320 dir_394806]$ pwd\n    /scratch/condor_pool/condor/dir_394806\n</code></pre> <p>Here the shell session of user <code>mrtest</code> was teleported to work-node <code>wn3801320</code> under the auspices of the HTCondor scheduler (hence the time limit). Note that the working directory <code>getenv=True</code> is not <code>mrtest</code>'s home directory on Noether! -- it is a scratch directory which is local to the node. Heavy IO work should be confined to these local scratch directories.  However, <code>mrtest</code> can easily access his cluster-wide home directory simply by issuing <code>cd</code>as follows:</p> <pre><code>    [mrtest@wn3801320 dir_394806]$ cd\n    [mrtest@wn3801320 ~]$ pwd       \n    /gluster/home/mrtest                            # Now in cluster-wide $HOME directory\n    [mrtest@wn3801320 ~]$ cd $_CONDOR_SCRATCH_DIR\n    [mrtest@wn3801320 dir_394806]$ pwd \n    /scratch/condor_pool/condor/dir_394806          # Now back in job-specific node-local scratch directory\n</code></pre> <p>It is thus necessary to copy critical code and data back into one's home or Lab directory before the interactive session terminates.</p>"},{"location":"noether_faq/","title":"Noether Compute Cluster: Frequently Asked Questions","text":""},{"location":"noether_faq/#section-a-general","title":"Section A. General","text":"<p>A1. What is Noether?</p> <p>Noether is the HEP Group's 'Tier3' end-user research computation cluster, consisting of several loosely-coupled physical and virtual machines. Shared home directory and data areas are mounted from a Gluster farm, and by using the HTCondor scheduler, users can run batch or interactive sessions on the cluster.</p> <p>A2. How do I request an account on Noether?</p> <p>Accounts have to be requested by your academic supervisor or line manager. Please ask them to send an email to [BLACKETT-SUPPORT] with you in CC, providing the following information about you: - Full name. - University of Manchester email address. - Role - Primary affiliation (experiment or project) - Expiry date of the account. - Required access to experimental or project data.</p> <p>If supervisors need accounts for multiple users, the admin team would appreciate it if they ask for them in one request rather than in individual requests. This will allow us to process them more efficiently.</p> <p>A3. How many work-nodes does Noether have and what are their memory and CPU specifications?</p> <p>There are presently 31 work-nodes: - 8 with 96 cores / 384GB RAM (4GB/core, Intel(R) Xeon(R) Gold 5220R CPU @ 2.20GHz). - 20 with 16 cores / 64 GB RAM (4GB/core, Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz). - 3 GPU nodes each with 3 Tesla V100 GPUs and 32 cores / 128 GB RAM (4GB/core, Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz).</p> <p>The total is therefore currently 1184 cores and 9 GPUs, though in practice this may vary somewhat as equipment is added, retired or placed under maintenance. </p>"},{"location":"noether_faq/#section-b-storage","title":"Section B. Storage","text":"<p>B1. What storage is available on Noether and what is its visibility?</p> <p>Globally visible data and home directory areas are available with a total capacity of 0.25 PB. Each work-node has a much smaller (and volatile) local 'scratch' area of around 7TB: you should only use 'scratch' as a staging area for ongoing batch work: all code and data you wish to retain on Noether must be copied to your home directory or shared data area.</p> <p>B2. Where should I place 'big data' on Noether?</p> <p>We have organised per-experiment data diretories on Noether, mounted under <code>/gluster/data</code>; all large datasets should be placed here for optimal access in computations. Your initial access to this area will correspond to your experimental affiliation. Access to additional areas will be granted upon request subjecxt to stakeholder approval.</p> <p>B3. What are the quotas for the Home and Data areas on Noether?</p> <p>All end-user home directories, which are to be found under <code>/gluster/home</code>, are assigned an initial capacity of 20GB, whereas the per-experiment data directories are assigned 10TB. This large datasets should not be kept in one's home directory. If you run over capacity you will be unable to create new files. You must either free up space or request in increase to your quota via the [BLACKETT-SUPPORT] list.</p> <p>B4. Are the Home and Data areas backed up?</p> <p>No they are not backed up presently: it is therefore essential that users of Noether ensure that all critical code and data are regularly <code>rsync</code>-ed (or otherwise transferred) to a secure and resilient out-of-band location, such as an encrypted external hard-drive.</p>"},{"location":"noether_faq/#section-c-usage","title":"Section C. Usage","text":"<p>C1. How do I connect to Noether?</p> <p>You must use an ssh-client to connect to Noether. If you use Linux or Mac OS then you may simply <code>ssh &lt;your_username&gt;@noether.hep.manchester.ac.uk</code>. The proceedure for resetting your initially assigned password is given in the email sent to you when your account is created. If you use Windows then it it recommended either to use PuTTy or the Windows Subsystem for Linux.</p> <p>C2. What is a typical workflow on Noether?</p> <p>Most users will wish to 'start small' in their home directory under an interactive htcondor session on one of the work-nodes. When code is running correctly, it is then matter of writing a shell-script and htcondor submission file to automate matters. In this way you may scale up your workflow, conduct parameterised 'sweeps' and so on.</p> <p>C3. How do I start an interactive session on a work-node?</p> <p>In brief, one issues <code>condor_submit -i</code> or simply <code>qrsh</code> to be 'teleported' to a work-node of Noether (a subset of work-nodes has been set aside for interactive sessions). More details are given in here</p> <p>C4. How do I submit a batch job into the HTCondor scheduler queue?</p> <p>A simple example of the use of HTCondor to run batch jobs is given ibid</p> <p>C5. How do I use the GPU-enabled work-nodes?</p> <p>That is very straightforward: for interactive sessions simply add <code>qrsh request_gpus=1</code> to your <code>qrsh</code> invocation. For batch jobs you may add <code>request_gpus=[1-3]</code> to either your <code>qsub</code> invocation or the corresponding <code>.sub</code> file for the job (the current batch GPU nodes have three such processors).</p>"},{"location":"noether_faq/#section-d-resource-limits","title":"Section D. Resource Limits","text":"<p>D1. How do I request such and such a CPU or memory resource for the job I submit?</p> <p>D2. How do I submit multiple parameterized copies of the same task into the queue?</p> <p>D3. What is the maximum number of jobs I may have running on work-nodes?</p>"},{"location":"noether_faq/#section-e-miscellany","title":"Section E. Miscellany","text":"<p>E1. What software applications are available on Noether.</p> <p>Not many at the moment: just standard Linux system utilities and what can be found by delving into CVMFS which is mounted cluster-wide.</p> <p>E2. I already have an account on the machines <code>pc2012, pc2013, pc1014, higgs</code> and the shared GPU machines. Can I use the same home directory on Noether?</p> <p>Unfortunately we cannot use the 'old-style' AFS home directories on Noether, but we can certainly assist with copying data across to the new infrastructure, subject to quota.</p>"},{"location":"user-web-pages/","title":"User web pages","text":"<p>Some users of the particle physics interactive cluster are able to publish web pages and other  files on users.hep.manchester.ac.uk However for most people, the University's  personal pages service or a  lab service like  CERN's AFS websites will be better options.</p> <p>To publish files on the particle physics users webserver, place the files in the WWW subdirectory  of your home directory on AFS. If your AFS username is EXAMPLE, then your personal website  appears at <code>https://users.hep.manchester.ac.uk/u/EXAMPLE/</code> . You can create subdirectories  within your WWW directory which appear as further subdirectories under /u/EXAMPLE/ on  the web. </p> <p>To make a web page, the file needs to be in HTML format with file extension .html .</p> <p>If a file index.html exists in a directory, then that page is displayed to viewers when they view web URLs ending in slash. For example, ~/WWW/test1/index.html will be displayed when viewers go to <code>https://users.hep.manchester.ac.uk/u/EXAMPLE/test1/</code>.</p> <p>Automatic directory listings are not supported. Files in a directory can be accessed by using the full link path. If you want to have a page with clickable links then you need to add them to an html file.</p> <p>The AFS directories should be readable by the AFS www:webservers group. This can be checked by going into the directory and executing the command <code>fs listacl</code> which should dislay a list  of permissions including www:webservers rl (read and list permissions). Your top level home directory also needs l (list) permission for www:webservers. If any of the permissions are missing, you can set them with <code>fs setacl -dir . -acl www:webservers rl</code>. For example, on a machine that uses the AFS as your home directory, the following commands set the correct permissions.</p> <pre><code>cd ~\nfs setacl -dir . -acl www:webservers l\nfs setacl -dir WWW -acl www:webservers rl\n</code></pre> <p>It is not possible to enable users websites to run CGI scripts, PHP pages, and other forms of server-side dynamic content. </p>"}]}